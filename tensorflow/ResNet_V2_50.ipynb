{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_V2_50.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cherryMonth/Neural-Networks/blob/master/tensorflow/ResNet_V2_50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6FVRilGUNbme",
        "colab_type": "code",
        "outputId": "4b4565c3-a9ae-4504-eacc-034f66062829",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "! wget http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz\n",
        "  \n",
        "! tar zxvf resnet_v2_50_2017_04_14.tar.gz\n",
        "\n",
        "! mkdir -p r2_new_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-30 05:35:48--  http://download.tensorflow.org/models/resnet_v2_50_2017_04_14.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.195.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.195.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 286441851 (273M) [application/x-tar]\n",
            "Saving to: ‘resnet_v2_50_2017_04_14.tar.gz’\n",
            "\n",
            "resnet_v2_50_2017_0 100%[===================>] 273.17M   151MB/s    in 1.8s    \n",
            "\n",
            "2019-01-30 05:35:50 (151 MB/s) - ‘resnet_v2_50_2017_04_14.tar.gz’ saved [286441851/286441851]\n",
            "\n",
            "resnet_v2_50.ckpt\n",
            "train.graph\n",
            "eval.graph\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Dz1h3u6N7t6",
        "colab_type": "code",
        "outputId": "ae72de24-5302-4cd0-bf9a-8b426ad0c82e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2677
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.contrib.slim import nets\n",
        "import numpy as np\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "from keras.datasets.cifar10 import load_data\n",
        "\n",
        "def color_preprocessing(x_train, x_test):\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    mean = [125.307, 122.95, 113.865]\n",
        "    std = [62.9932, 62.0887, 66.7048]\n",
        "    for i in range(3):\n",
        "        x_train[:, :, :, i] = (x_train[:, :, :, i] - mean[i]) / std[i]\n",
        "        x_test[:, :, :, i] = (x_test[:, :, :, i] - mean[i]) / std[i]\n",
        "    return x_train, x_test\n",
        "\n",
        "class ShowProcess():\n",
        "    \"\"\"\n",
        "    显示处理进度的类\n",
        "    调用该类相关函数即可实现处理进度的显示\n",
        "    \"\"\"\n",
        "    i = 0  # 当前的处理进度\n",
        "    max_steps = 0  # 总共需要处理的次数\n",
        "    max_arrow = 50  # 进度条的长度\n",
        "    infoDone = 'done'\n",
        "\n",
        "    # 初始化函数，需要知道总共的处理次数\n",
        "    def __init__(self, max_steps):\n",
        "        self.max_steps = max_steps\n",
        "        self.i = 0\n",
        "\n",
        "    # 显示函数，根据当前的处理进度i显示进度\n",
        "    # 效果为[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%\n",
        "    def show_process(self, info, i=None):\n",
        "        if i is not None:\n",
        "            self.i = i\n",
        "        else:\n",
        "            self.i += 1\n",
        "        num_arrow = int(self.i * self.max_arrow / self.max_steps)  # 计算显示多少个'>'\n",
        "        num_line = self.max_arrow - num_arrow  # 计算显示多少个'-'\n",
        "        percent = self.i * 100.0 / self.max_steps  # 计算完成进度，格式为xx.xx%\n",
        "        process_bar = '\\r[' + '>' * num_arrow + '-' * num_line + ']' \\\n",
        "                      + '%.2f' % percent + '%  ' + info  # 带输出的字符串，'\\r'表示不换行回到最左边\n",
        "        print(process_bar, end='')  # 这两句打印字符到终端\n",
        "        if self.i > self.max_steps:\n",
        "            self.close()\n",
        "\n",
        "    def close(self):\n",
        "        print(\"\\n\")  # 训练完一行记录之后跳转到下一行\n",
        "        self.i = 0\n",
        "\n",
        "n_epochs = 70\n",
        "batch_size = 128\n",
        "iterations = 50000 // batch_size + 1\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = load_data()  # 50000, 32,32,3\n",
        "y_train = np.array(keras.utils.to_categorical(y_train, 10).tolist())\n",
        "y_test = np.array(keras.utils.to_categorical(y_test, 10).tolist())\n",
        "x_train, x_test = color_preprocessing(x_train, x_test)\n",
        "x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "is_training = tf.placeholder(tf.bool, shape=[])\n",
        "p = ShowProcess(iterations)\n",
        "\n",
        "# Specify which gpu to be used\n",
        "\n",
        "resnet_model_path = 'resnet_v2_50.ckpt'  # Path to the pretrained model\n",
        "model_save_path = 'r2_new_model/model'  # 命名规则是路径名 + 模型名称\n",
        "\n",
        "is_training = tf.placeholder(tf.bool, name='is_training')\n",
        "\n",
        "with slim.arg_scope(nets.resnet_v2.resnet_arg_scope()):\n",
        "    net, endpoints = nets.resnet_v2.resnet_v2_50(x, num_classes=None, is_training=is_training)\n",
        "    \n",
        "net = slim.conv2d(net, 10, [1, 1], activation_fn=None, normalizer_fn=None, scope='fc')\n",
        "net = tf.squeeze(net, [1, 2], name=\"SpatialSqueeze\")\n",
        "\n",
        "checkpoint_exclude_scopes = 'Logits'\n",
        "exclusions = None\n",
        "if checkpoint_exclude_scopes:\n",
        "  exclusions = [\n",
        "      scope.strip() for scope in checkpoint_exclude_scopes.split(',')]\n",
        "variables_to_restore = []\n",
        "for var in slim.get_model_variables():\n",
        "  excluded = False\n",
        "  for exclusion in exclusions:\n",
        "      if var.op.name.startswith(exclusion):\n",
        "          excluded = True\n",
        "  if not excluded and var.op.name not in ['fc/weights', 'fc/biases']:  # 下载的模型不含有这两个参数，很奇怪,所以如果要使用模型，就需要把这两个参赛去掉\n",
        "      variables_to_restore.append(var)\n",
        "\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=net))\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(net, 1), tf.argmax(y, 1)), dtype=tf.float32))\n",
        "\n",
        "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "with tf.control_dependencies(update_ops):\n",
        "  optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(loss)\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "saver_restore = tf.train.Saver(var_list=variables_to_restore)\n",
        "\n",
        "# config = tf.ConfigProto(allow_soft_placement = True) \n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    # Load the pretrained checkpoint file xxx.ckpt\n",
        "    saver_restore.restore(sess, resnet_model_path)\n",
        "\n",
        "    for epoch_i in range(n_epochs):\n",
        "      result = None\n",
        "      average_result = 0.0\n",
        "      average_loss = 0.0\n",
        "      count = 0\n",
        "      k = 0\n",
        "      for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=batch_size):\n",
        "          result = sess.run([optimizer, accuracy, loss], feed_dict={x: x_batch, y: y_batch, is_training: True})\n",
        "          average_result += result[1]\n",
        "          average_loss += result[2]\n",
        "          p.show_process('epoch: {}, step: {}, loss: {:.3f}, acc: {:.2f}'.format(epoch_i + 1,\n",
        "                                                                                 k + 1, result[2], result[1], 3), k)\n",
        "          k += 1\n",
        "          if k == iterations: break\n",
        "\n",
        "      average_result /= iterations\n",
        "      average_loss /= iterations\n",
        "      if epoch_i % 10 == 0:\n",
        "          saver = tf.train.Saver(tf.global_variables())\n",
        "          save_path = saver.save(sess, model_save_path)\n",
        "      result = sess.run([accuracy, loss], feed_dict={x: x_test, y: y_test, is_training: False})\n",
        "      info = \"epoch: {}, step:{}, average-loss: {:.3f}, average-acc: {:.2f}, val_loss: {:.3f}, val_acc: {:.2f}\".format(\n",
        "          epoch_i,\n",
        "          k + 1,\n",
        "          average_loss,\n",
        "          average_result,\n",
        "          result[1],\n",
        "          result[0])\n",
        "      p.show_process(info, iterations)\n",
        "      p.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-e2a16d821b16>:93: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from resnet_v2_50.ckpt\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 0, step:392, average-loss: 1.832, average-acc: 0.36, val_loss: 1.526, val_acc: 0.46\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 1, step:392, average-loss: 1.166, average-acc: 0.60, val_loss: 1.109, val_acc: 0.62\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 2, step:392, average-loss: 0.963, average-acc: 0.67, val_loss: 0.873, val_acc: 0.70\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 3, step:392, average-loss: 0.858, average-acc: 0.70, val_loss: 0.803, val_acc: 0.74\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 4, step:392, average-loss: 0.786, average-acc: 0.73, val_loss: 0.739, val_acc: 0.75\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 5, step:392, average-loss: 0.742, average-acc: 0.74, val_loss: 0.705, val_acc: 0.76\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 6, step:392, average-loss: 0.694, average-acc: 0.76, val_loss: 0.651, val_acc: 0.78\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 7, step:392, average-loss: 0.663, average-acc: 0.77, val_loss: 0.716, val_acc: 0.76\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 8, step:392, average-loss: 0.632, average-acc: 0.78, val_loss: 0.598, val_acc: 0.80\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 9, step:392, average-loss: 0.604, average-acc: 0.79, val_loss: 0.616, val_acc: 0.79\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 10, step:392, average-loss: 0.584, average-acc: 0.80, val_loss: 0.630, val_acc: 0.79\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 11, step:392, average-loss: 0.559, average-acc: 0.81, val_loss: 0.675, val_acc: 0.78\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 12, step:392, average-loss: 0.548, average-acc: 0.81, val_loss: 0.595, val_acc: 0.80\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 13, step:392, average-loss: 0.525, average-acc: 0.82, val_loss: 0.577, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 14, step:392, average-loss: 0.508, average-acc: 0.82, val_loss: 0.598, val_acc: 0.80\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 15, step:392, average-loss: 0.499, average-acc: 0.83, val_loss: 0.567, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 16, step:392, average-loss: 0.474, average-acc: 0.83, val_loss: 0.582, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 17, step:392, average-loss: 0.466, average-acc: 0.84, val_loss: 0.600, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 18, step:392, average-loss: 0.454, average-acc: 0.84, val_loss: 0.681, val_acc: 0.79\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 19, step:392, average-loss: 0.439, average-acc: 0.84, val_loss: 0.604, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 20, step:392, average-loss: 0.427, average-acc: 0.85, val_loss: 0.532, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 21, step:392, average-loss: 0.413, average-acc: 0.86, val_loss: 0.569, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 22, step:392, average-loss: 0.407, average-acc: 0.86, val_loss: 0.609, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 23, step:392, average-loss: 0.395, average-acc: 0.86, val_loss: 0.519, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 24, step:392, average-loss: 0.384, average-acc: 0.86, val_loss: 0.563, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 25, step:392, average-loss: 0.373, average-acc: 0.87, val_loss: 0.589, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 26, step:392, average-loss: 0.363, average-acc: 0.87, val_loss: 0.564, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 27, step:392, average-loss: 0.355, average-acc: 0.88, val_loss: 0.586, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 28, step:392, average-loss: 0.347, average-acc: 0.88, val_loss: 0.565, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 29, step:392, average-loss: 0.336, average-acc: 0.88, val_loss: 0.574, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 30, step:392, average-loss: 0.327, average-acc: 0.88, val_loss: 0.587, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 31, step:392, average-loss: 0.318, average-acc: 0.89, val_loss: 0.528, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 32, step:392, average-loss: 0.316, average-acc: 0.89, val_loss: 0.551, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 33, step:392, average-loss: 0.310, average-acc: 0.89, val_loss: 0.570, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 34, step:392, average-loss: 0.298, average-acc: 0.89, val_loss: 0.584, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 35, step:392, average-loss: 0.296, average-acc: 0.90, val_loss: 0.625, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 36, step:392, average-loss: 0.292, average-acc: 0.90, val_loss: 0.600, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 37, step:392, average-loss: 0.277, average-acc: 0.90, val_loss: 0.577, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 38, step:392, average-loss: 0.269, average-acc: 0.90, val_loss: 0.639, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 39, step:392, average-loss: 0.266, average-acc: 0.91, val_loss: 0.574, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 40, step:392, average-loss: 0.265, average-acc: 0.91, val_loss: 0.611, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 41, step:392, average-loss: 0.253, average-acc: 0.91, val_loss: 0.596, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 42, step:392, average-loss: 0.252, average-acc: 0.91, val_loss: 0.620, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 43, step:392, average-loss: 0.243, average-acc: 0.91, val_loss: 0.597, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 44, step:392, average-loss: 0.241, average-acc: 0.91, val_loss: 0.609, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 45, step:392, average-loss: 0.235, average-acc: 0.92, val_loss: 0.701, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 46, step:392, average-loss: 0.227, average-acc: 0.92, val_loss: 0.618, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 47, step:392, average-loss: 0.225, average-acc: 0.92, val_loss: 0.647, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 48, step:392, average-loss: 0.224, average-acc: 0.92, val_loss: 0.645, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 49, step:392, average-loss: 0.216, average-acc: 0.92, val_loss: 0.627, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 50, step:392, average-loss: 0.212, average-acc: 0.93, val_loss: 0.600, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 51, step:392, average-loss: 0.204, average-acc: 0.93, val_loss: 0.636, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 52, step:392, average-loss: 0.204, average-acc: 0.93, val_loss: 0.636, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 53, step:392, average-loss: 0.199, average-acc: 0.93, val_loss: 0.649, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 54, step:392, average-loss: 0.196, average-acc: 0.93, val_loss: 0.652, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 55, step:392, average-loss: 0.189, average-acc: 0.93, val_loss: 0.698, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 56, step:392, average-loss: 0.189, average-acc: 0.94, val_loss: 0.660, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 57, step:392, average-loss: 0.188, average-acc: 0.94, val_loss: 0.651, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 58, step:392, average-loss: 0.189, average-acc: 0.93, val_loss: 0.667, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 59, step:392, average-loss: 0.182, average-acc: 0.94, val_loss: 0.672, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 60, step:392, average-loss: 0.181, average-acc: 0.94, val_loss: 0.652, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 61, step:392, average-loss: 0.173, average-acc: 0.94, val_loss: 0.701, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 62, step:392, average-loss: 0.171, average-acc: 0.94, val_loss: 0.643, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 63, step:392, average-loss: 0.168, average-acc: 0.94, val_loss: 0.679, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 64, step:392, average-loss: 0.173, average-acc: 0.94, val_loss: 0.640, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 65, step:392, average-loss: 0.161, average-acc: 0.94, val_loss: 0.755, val_acc: 0.81\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 66, step:392, average-loss: 0.162, average-acc: 0.94, val_loss: 0.722, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 67, step:392, average-loss: 0.159, average-acc: 0.94, val_loss: 0.691, val_acc: 0.82\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 68, step:392, average-loss: 0.153, average-acc: 0.95, val_loss: 0.673, val_acc: 0.83\n",
            "\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>]100.00%  epoch: 69, step:392, average-loss: 0.153, average-acc: 0.95, val_loss: 0.720, val_acc: 0.82\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-nf3ACZxjXqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1HiBzriXPmV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}